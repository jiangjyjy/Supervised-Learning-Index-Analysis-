# Supervised-Learning-Index-Analysis-

备注：为了更好的让大家去学习，代码并非全部代码，部分代码框架，可以跟我进行联系进行学习
我的邮箱：jiyuejiang2020@163.com

使用逻辑回归、决策树、神经网络、支持向量机四个模型在该数据集上进行对比评测。

原理简单介绍:
（1）逻辑回归的原理简单介绍
如果直接将线性回归的模型扣到逻辑回归中，会造成方程二边取值区间不同和普遍的非直线关系。因为Logistic中因变量为二分类变量，某个概率作为方程的因变量估计值取值范围为（0，1），但是，方程右边取值范围是无穷大或者无穷小。所以，才引入逻辑回归。
（2）决策树的原理简单分析
决策树是一个预测模型；他代表的是对象属性与对象值之间的一种映射关系。树中每个节点表示某个对象，而每个分叉路径则代表的某个可能的属性值，而每个叶结点则对应从根节点到该叶节点所经历的路径所表示的对象的值。决策树仅有单一输出，若欲有复数输出，可以建立独立的决策树以处理不同输出。数据挖掘中决策树是一种经常要用到的技术，可以用于分析数据，同样也可以用来作预测。
（3）神经网络的原理简单分析
人工神经网络（ANN）是一种算法结构，使得机器能够学习一切，从语音命令、播放列表到音乐创作和图像识别。典型的 ANN 由数千个互连的人造神经元组成，它们按顺序堆叠在一起，以称为层的形式形成数百万个连接。在许多情况下，层仅通过输入和输出与它们之前和之后的神经元层互连。（这与人类大脑中的神经元有很大的不同，它们的互连是全方位的）。
（4）支持向量机简单分析
支持向量机，作为传统机器学习的一个非常重要的分类算法，它是一种通用的前馈网络类型，最早是由Vladimir N.Vapnik 和 Alexey Ya.Chervonenkis在1963年提出，目前的版本（soft margin）是Corinna Cortes 和 Vapnik在1993年提出，1995年发表。深度学习出现之前，如果不考虑集成学习的算法，不考虑特定的训练数据集，在分类算法中的表现SVM说是排第一估计是没有什么异议的。SVM本来是一种线性分类和非线性分类都支持的二元分类算法，但经过演变，现在也支持多分类问题，也能应用到了回归问题。

 · 分类任务使用的是Iris Data Set（鸢尾属植物数据集）：
Iris Data Set（鸢尾属植物数据集）是现在接触到的历史最悠久的数据集，它首次出现在著名的英国统计学家和生物学家Ronald Fisher 1936年的论文《The use of multiple measurements in taxonomic problems》中，被用来介绍线性判别式分析。在这个数据集中，包括了三类不同的鸢尾属植物：Iris Setosa，Iris Versicolour，Iris Virginica。每类收集了50个样本，因此这个数据集一共包含了150个样本。
该数据集测量了所有150个样本的4个特征，分别是：
sepal length（花萼长度）；
sepal width（花萼宽度）；
petal length（花瓣长度）；
petal width（花瓣宽度）；
以上四个特征的单位都是厘米（cm）。
通常使用m表示样本量的大小，n表示每个样本所具有的特征数。因此在该数据集中，m=150，n=4。

 · 回归任务使用的是波士顿房价数据集（Boston House Price Dataset）：
该数据集是一个回归问题。每个类的观察值数量是均等的，共有 506 个观察，13 个输入变量和1个输出变量。每条数据包含房屋以及房屋周围的详细信息。其中包含城镇犯罪率，一氧化氮浓度，住宅平均房间数，到中心区域的加权距离以及自住房平均房价等等。
